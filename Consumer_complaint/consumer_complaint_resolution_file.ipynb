{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPpvecwEpopQ"
      },
      "source": [
        "## Mini Project 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdiFBmcBpopt"
      },
      "source": [
        "Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRvORrhJpopv"
      },
      "outputs": [],
      "source": [
        " import pandas as pd\n",
        " import datetime as dt\n",
        " from sklearn.tree import DecisionTreeRegressor\n",
        " from sklearn.metrics import mean_absolute_error\n",
        " from sklearn.model_selection import train_test_split\n",
        " from sklearn.ensemble import RandomForestRegressor\n",
        " import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9psaFBmPpop0"
      },
      "source": [
        "Load given datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "te_file_path ='/content/sample_data/Consumer_Complaints_test.csv'\n",
        "tr_file_path ='/content/sample_data/Consumer_Complaints_train.csv'"
      ],
      "metadata": {
        "id": "3VunxEz7eSgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data = pd.read_csv(tr_file_path)\n",
        "te_data = pd.read_csv(te_file_path)"
      ],
      "metadata": {
        "id": "FsSbfJnXe7ta",
        "outputId": "03b5bd5a-f93a-4124-cc5d-423f2f31a7f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3854d84b6336>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtr_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mte_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mte_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/sample_data/Consumer_Complaints_train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp8W3eXcpop5"
      },
      "source": [
        "Print top 5 records of train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1b67V24pop6"
      },
      "outputs": [],
      "source": [
        "tr_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vy0goz35pop7"
      },
      "source": [
        "Print top 5 records of test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1GqR9Agpop9"
      },
      "outputs": [],
      "source": [
        "te_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzRBJoR7pop-"
      },
      "source": [
        "**Note: Please note that do all given tasks for test and train both datasets.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbq7pvmGpop_"
      },
      "source": [
        "Print shape of train and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFPXZRfMpoqA"
      },
      "outputs": [],
      "source": [
        "te_data.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data.shape"
      ],
      "metadata": {
        "id": "YEwowOcmbYgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oPnYhOapoqA"
      },
      "source": [
        "Print columns of train and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPzUL5fUpoqB"
      },
      "outputs": [],
      "source": [
        "for col in tr_data.columns:\n",
        "    print(col)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for col in te_data.columns:\n",
        "    print(col)"
      ],
      "metadata": {
        "id": "MIFg0q2Jjz9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HiyNNaKpoqC"
      },
      "source": [
        "Check data type for both datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxGdAynspoqC"
      },
      "outputs": [],
      "source": [
        "tr_data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "te_data.dtypes"
      ],
      "metadata": {
        "id": "8udxR3BVkY0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLuxvPTupoqD"
      },
      "source": [
        "Print missing values in percentage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGG5jiynpoqD"
      },
      "outputs": [],
      "source": [
        "tr_data.isnull()\n",
        "te_data.isnull()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "round(100*(tr_data.isna().sum()/len(tr_data)),1)"
      ],
      "metadata": {
        "id": "MbdBGuL9Gqzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "round(100*(te_data.isna().sum()/len(te_data)),1)"
      ],
      "metadata": {
        "id": "L49O3NkBGvuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_count =  int(((100-25)/100)*tr_data.shape[0] + 1)\n",
        "tr_data = tr_data.dropna( axis=1, thresh=min_count)"
      ],
      "metadata": {
        "id": "gktIAEj8GyG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_count =  int(((100-25)/100)*te_data.shape[0] + 1)\n",
        "te_data = te_data.dropna( axis=1, thresh=min_count)"
      ],
      "metadata": {
        "id": "0X0-0t__G0Sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data.head()"
      ],
      "metadata": {
        "id": "4zWXsng8G4bG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJhBaNOqpoqG"
      },
      "outputs": [],
      "source": [
        "te_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkddP08zpoqI"
      },
      "source": [
        "Extract Date, Month, and Year from the \"Date Received\" Column and create new fields for year, month, and day.\n",
        "\n",
        "like, df_train['Year_Received'] = df_train['Date received']........(logic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-f5_sc8poqM"
      },
      "outputs": [],
      "source": [
        "tr_data['Date received']=tr_data['Date received'].apply(pd.to_datetime)\n",
        "tr_data['Day']=tr_data['Date received'].dt.day\n",
        "tr_data['Month']=tr_data['Date received'].dt.month\n",
        "tr_data['Year']=tr_data['Date received'].dt.year"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data.head()"
      ],
      "metadata": {
        "id": "M6pFAITzqmhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "te_data['Date received']=te_data['Date received'].apply(pd.to_datetime)\n",
        "te_data['Day']=te_data['Date received'].dt.day\n",
        "te_data['Month']=te_data['Date received'].dt.month\n",
        "te_data['Year']=te_data['Date received'].dt.year"
      ],
      "metadata": {
        "id": "sseJuzC1rFjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "te_data.head()"
      ],
      "metadata": {
        "id": "16HOZHrOIxUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDzo8Q5HpoqN"
      },
      "source": [
        "Convert dates from object type to datetime type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-rUlAE3poqN"
      },
      "outputs": [],
      "source": [
        "te_data['Date received'] = pd.to_datetime(te_data['Date received'] )\n",
        "te_data['Date sent to company'] = pd.to_datetime(te_data['Date sent to company'] )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data['Date received'] = pd.to_datetime(tr_data['Date received'] )\n",
        "tr_data['Date sent to company'] = pd.to_datetime(tr_data['Date sent to company'] )"
      ],
      "metadata": {
        "id": "s3YgvuY1JSkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7ZhXjgWpoqO"
      },
      "source": [
        "Calculate the number of days the complaint was with the company\n",
        "\n",
        "create new field with help given logic<br>\n",
        "Like, Days held = Date sent to company - Date received"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tZ5kgp5poqO"
      },
      "outputs": [],
      "source": [
        "tr_data['Days held']=tr_data['Date sent to company']-tr_data['Date received']\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "te_data['Days held']=te_data['Date sent to company']-tr_data['Date received']\n"
      ],
      "metadata": {
        "id": "sgCisOzjul6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU-KOCtopoqO"
      },
      "source": [
        "Convert \"Days Held\" to Int(above column)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "te_data['Days held'] =te_data['Days held'].dt.days"
      ],
      "metadata": {
        "id": "-Y07tBMNvO5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data['Days held'] =tr_data['Days held'].dt.days"
      ],
      "metadata": {
        "id": "81fq13eMwsrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data.head()"
      ],
      "metadata": {
        "id": "r2ifekpOKNfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HQaa_05poqP"
      },
      "source": [
        "Drop \"Date Received\",\"Date Sent to Company\",\"ZIP Code\", \"Complaint ID\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9WmzyvmpoqQ"
      },
      "outputs": [],
      "source": [
        "te_data= te_data.drop(['Date received','Date sent to company','ZIP code', 'Complaint ID'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data= tr_data.drop(['Date received','Date sent to company','ZIP code', 'Complaint ID'],axis=1)"
      ],
      "metadata": {
        "id": "aG5I_YN4p03p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "te_data.head()"
      ],
      "metadata": {
        "id": "_vxYfUWYNLyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXrMeXGGpoqQ"
      },
      "source": [
        "Impute null values in \"State\" by Mode\n",
        "(find mode and replace nan value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2E50Tq6qpoqQ"
      },
      "outputs": [],
      "source": [
        "tr_data['State'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data['State'] = tr_data['State'].fillna(tr_data['State'].mode()[0])"
      ],
      "metadata": {
        "id": "p6fm83wVNrFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data['State'].isna().sum()"
      ],
      "metadata": {
        "id": "pmdh8pmON0UX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data"
      ],
      "metadata": {
        "id": "Fqp5CH0_N54F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "te_data['State'].isna().sum()"
      ],
      "metadata": {
        "id": "9nEeufJSN--G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "te_data['State'] = te_data['State'].fillna(tr_data['State'].mode()[0])"
      ],
      "metadata": {
        "id": "2btUHClIOFGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "te_data['State'].isna().sum()"
      ],
      "metadata": {
        "id": "EQ6f9qoEOFKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "te_data"
      ],
      "metadata": {
        "id": "h6b7HeRKOOvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDDfIGddpoqR"
      },
      "source": [
        "Check Missing Values in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lHuVu79poqR"
      },
      "outputs": [],
      "source": [
        "tr_data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "te_data.isna().sum()"
      ],
      "metadata": {
        "id": "pyhsHqTAOaQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0EPXTRWpoqR"
      },
      "source": [
        "Categorize Days into Weeks with the help of 'Days Received'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zr7y3qkCpoqS"
      },
      "outputs": [],
      "source": [
        "tr_data['Date'] = pd.to_datetime(dict(year=tr_data['Year'], month=tr_data['Month'], day=tr_data['Day']))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data['Date']=tr_data['Date'].apply(pd.to_datetime)\n",
        "tr_data[\"Weeks\"] = tr_data['Date'].dt.week"
      ],
      "metadata": {
        "id": "UrPdIECjYvst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data"
      ],
      "metadata": {
        "id": "TBgYD9e-ZKt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "te_data['Date'] = pd.to_datetime(dict(year=te_data['Year'], month=te_data['Month'], day=te_data['Day']))"
      ],
      "metadata": {
        "id": "wOJtv0kuZhwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "te_data['Date']=te_data['Date'].apply(pd.to_datetime)\n",
        "te_data[\"Weeks\"] = te_data['Date'].dt.week"
      ],
      "metadata": {
        "id": "GtiOryl9ZibI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "te_data"
      ],
      "metadata": {
        "id": "taBdHqSZZimC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUZBAfyopoqS"
      },
      "source": [
        "Drop \"Day_Received\" column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5ka68OnpoqT"
      },
      "outputs": [],
      "source": [
        "tr_data=tr_data.drop(['Date'],axis=1)\n",
        "te_data=te_data.drop(['Date'],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYdZ9SulpoqT"
      },
      "source": [
        "Print head of train and test dataset and observe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Njal7vDbpoqT"
      },
      "outputs": [],
      "source": [
        "tr_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "te_data.head()"
      ],
      "metadata": {
        "id": "CqQWhZaQanP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8tqx2qCpoqT"
      },
      "source": [
        "Store data of the disputed consumer in the new data frame as \"disputed_cons\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIsh5bhipoqU"
      },
      "outputs": [],
      "source": [
        "disputed_cons_tr=tr_data.copy()\n",
        "disputed_cons_te=te_data.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtGG1fslpoqU"
      },
      "source": [
        "Plot bar graph for the total no of disputes with the help of seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aawMOyG5poqW"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.countplot(data=tr_data, x='Consumer disputed?')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCZyWAkUpoqW"
      },
      "source": [
        "Plot bar graph for the total no of disputes products-wise with help of seaborn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax = plt.subplots(figsize=(22,6))\n",
        "sns.countplot(x=tr_data[tr_data['Consumer disputed?'] == 'Yes']['Product'],data=tr_data)"
      ],
      "metadata": {
        "id": "vDZTKZrazq-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0U3hAu4poqY"
      },
      "source": [
        "Plot bar graph for the total no of disputes with Top Issues by Highest Disputes , with help of seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hx_k7HkYpoqY"
      },
      "outputs": [],
      "source": [
        "# sns.countplot(y='Issue',data=tr_data)\n",
        "# tr_data[tr_data['Consumer disputed?'] == 'Yes']['Issue'].value_counts().plot(kind='bar',figsize=(33,10))\n",
        "fig,ax = plt.subplots(figsize=(22,6))\n",
        "sns.countplot(x=tr_data[tr_data['Consumer disputed?'] == 'Yes']['Issue'],data=tr_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lnfp_e9ZpoqY"
      },
      "source": [
        "Plot bar graph for the total no of disputes by State with Maximum Disputes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YieTWCtpoqZ"
      },
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots(figsize=(22,6))\n",
        "sns.countplot(x=tr_data[tr_data['Consumer disputed?'] == 'Yes']['State'],data=tr_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzYlsiEFpoqZ"
      },
      "source": [
        "Plot bar graph for the total no of disputes by Submitted Via diffrent source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShPK2OoepoqZ"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x=tr_data[tr_data['Consumer disputed?'] == 'Yes']['Submitted via'],data=tr_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rl_JZPCipoqa"
      },
      "source": [
        "Plot bar graph for the total no of disputes wherevCompany's Response to the Complaints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XTLjfbtpoqa"
      },
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots(figsize=(20,5))\n",
        "sns.countplot(x=tr_data[tr_data['Consumer disputed?'] == 'Yes']['Company response to consumer'],data=tr_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGvHtAP2poqa"
      },
      "source": [
        "Plot bar graph for the total no of disputes where Company's Response Leading to Disputes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MdIaJKJpoqa"
      },
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots(figsize=(20,6))\n",
        "sns.countplot(x=tr_data[tr_data['Consumer disputed?'] == 'Yes']['Company response to consumer'],data=tr_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myL-cp2Dpoqb"
      },
      "source": [
        "Plot bar graph for the total no of disputes Whether there are Disputes Instead of Timely Response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyPJWgZUpoqb"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x=tr_data[tr_data['Consumer disputed?'] == 'Yes']['Timely response?'],data=tr_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t91R-deppoqb"
      },
      "source": [
        "Plot bar graph for the total no of disputes over Year Wise Complaints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGBscEOJpoqb"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x=tr_data[tr_data['Consumer disputed?'] == 'Yes']['Year'],data=tr_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT4ZwSo0poqc"
      },
      "source": [
        "Plot bar graph for the total no of disputes over Year Wise Disputes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADdy8Zavpoqc"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x=tr_data[tr_data['Consumer disputed?'] == 'Yes']['Year'],data=tr_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pCBYQhTpoqc"
      },
      "source": [
        "Plot  bar graph for the top companies with highest complaints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ovADVRSpoqc"
      },
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots(figsize=(60,30))\n",
        "sns.countplot(x=tr_data[tr_data['Consumer disputed?'] == 'Yes']['Company'],data=tr_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_VB1_2Qpoqc"
      },
      "source": [
        "\"Days Held\" Column Analysis(describe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fan0xohapoqd"
      },
      "outputs": [],
      "source": [
        "tr_data['Days held'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "te_data['Days held'].describe()"
      ],
      "metadata": {
        "id": "ZhmNUwFxppKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlLBckNcpoqd"
      },
      "source": [
        "Convert Negative Days Held to Zero(it is the time taken by authority can't be negative)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Phr6eNn6poqd"
      },
      "source": [
        "Drop Days Held with Negative Values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data[\"Days held\"] = np.where(tr_data[\"Days held\"]<=0,0,tr_data['Days held'])\n",
        "tr_data['Days held'].describe()"
      ],
      "metadata": {
        "id": "rkdawlIE13sI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data"
      ],
      "metadata": {
        "id": "35ZmR3N_2i9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "te_data[\"Days held\"] = np.where(te_data[\"Days held\"]<=0,0,te_data['Days held'])\n",
        "te_data['Days held'].describe()"
      ],
      "metadata": {
        "id": "rAhazxxo2rv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "te_data"
      ],
      "metadata": {
        "id": "ci1MJvgO2r8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPGVV2cypoqe"
      },
      "source": [
        "Text pre-processing\n",
        "(It will be cover in upcoming calsses)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textblob\n",
        "!pip install nltk\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import TextBlob\n",
        "from textblob import Word"
      ],
      "metadata": {
        "id": "OGa6aXgbQlcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "from nltk.tokenize import word_tokenize\n",
        "sw = stopwords.words(\"english\")\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import wordpunct_tokenize\n"
      ],
      "metadata": {
        "id": "y1b9XpqtPJXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUs9mtE-poqe"
      },
      "outputs": [],
      "source": [
        "\n",
        "relevant_text_train = tr_data['Issue']\n",
        "relevant_text_test = te_data['Issue']\n",
        "tokenized_data_train = relevant_text_train.apply(lambda x: wordpunct_tokenize(x.lower()))\n",
        "tokenized_data_test = relevant_text_test.apply(lambda x: wordpunct_tokenize(x.lower()))\n",
        "print(tokenized_data_train)\n",
        "print(tokenized_data_test)\n",
        "def remove_punctuation(text):\n",
        "    no_punctuation = []\n",
        "    for w in text:\n",
        "        if w not in string.punctuation:\n",
        "            no_punctuation.append(w)\n",
        "    return no_punctuation\n",
        "no_punctuation_data_train = tokenized_data_train.apply(lambda x: remove_punctuation(x))\n",
        "no_punctuation_data_test = tokenized_data_test.apply(lambda x: remove_punctuation(x))\n",
        "print(\"2\")\n",
        "print(no_punctuation_data_train)\n",
        "print(no_punctuation_data_test)\n",
        "stop_words = stopwords.words('english')\n",
        "filtered_sentence_train = [w for w in no_punctuation_data_train if not w in stop_words]\n",
        "filtered_sentence_train = pd.Series(filtered_sentence_train)\n",
        "filtered_sentence_test = [w for w in no_punctuation_data_test if not w in stop_words]\n",
        "filtered_sentence_test = pd.Series(filtered_sentence_test)\n",
        "print(\"3\")\n",
        "print(filtered_sentence_train)\n",
        "print(filtered_sentence_test)\n",
        "def lemmatize_text(text):\n",
        "    lem_text = [WordNetLemmatizer().lemmatize(w,pos = 'v') for w in text]\n",
        "    return lem_text\n",
        "lemmatized_data_train = filtered_sentence_train.apply(lambda x:lemmatize_text(x))\n",
        "lemmatized_data_test = filtered_sentence_test.apply(lambda x:lemmatize_text(x))\n",
        "print(\"4\")\n",
        "print(lemmatized_data_train)\n",
        "print(lemmatized_data_test)\n",
        "def stem_text(text):\n",
        "    stem_text = [PorterStemmer().stem(w) for w in text]\n",
        "    return stem_text\n",
        "stemmed_data_train = lemmatized_data_train.apply(lambda x:stem_text(x))\n",
        "stemmed_data_test = lemmatized_data_test.apply(lambda x:stem_text(x))\n",
        "print(\"5\")\n",
        "print(stemmed_data_train)\n",
        "print(stemmed_data_test)\n",
        "def word_to_sentence(text):\n",
        "    text_sentence = \" \".join(text)\n",
        "    return text_sentence\n",
        "clean_data_train = stemmed_data_train.apply(lambda x:word_to_sentence(x))\n",
        "clean_data_test = stemmed_data_test.apply(lambda x:word_to_sentence(x))\n",
        "print(\"6\")\n",
        "print(clean_data_train)\n",
        "print(clean_data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFlUCeGxpoqf"
      },
      "outputs": [],
      "source": [
        "tr_data['Issues_cleaned'] = clean_data_train\n",
        "tr_data = tr_data.drop('Issue', axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "te_data['Issues_cleaned'] = clean_data_test\n",
        "te_data = te_data.drop('Issue', axis = 1)"
      ],
      "metadata": {
        "id": "chy7uuEghN7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data"
      ],
      "metadata": {
        "id": "sVlCD-myhlTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7h1ZLZwSpoqg"
      },
      "source": [
        "Drop Unnecessary Columns for the Model Building<br>\n",
        "like:'Company', 'State', 'Year_Received', 'Days_held'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAhztPQ9poqg"
      },
      "outputs": [],
      "source": [
        "tr_data = tr_data.drop(['Company','State','Year','Days held'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "te_data = te_data.drop(['Company','State','Year','Days held'], axis = 1)"
      ],
      "metadata": {
        "id": "Um9TRxdvlxPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbQVqtzqpoqg"
      },
      "source": [
        "Change Consumer Disputed Column to 0 and 1(yes to 1, and no to 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data[\"Consumer disputed?\"] = np.where(tr_data[\"Consumer disputed?\"]==\"Yes\",1,0)"
      ],
      "metadata": {
        "id": "TS4suymCmD4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "te_data"
      ],
      "metadata": {
        "id": "VTpIvlJ0LzlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data"
      ],
      "metadata": {
        "id": "QnHBVw81PBXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf3IZk9Upoqh"
      },
      "source": [
        "Create Dummy Variables for catagorical features\n",
        "like: 'Product', 'Submitted via', 'Company response to consumer', 'Timely response?'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_dummies=pd.get_dummies(tr_data, prefix=['Product_dumb', 'Submitted via_dumb', 'Company response to consumer_dumb', 'Timely response?_dumb'], columns=['Product', 'Submitted via', 'Company response to consumer', 'Timely response?'])"
      ],
      "metadata": {
        "id": "1bw-nEv4orOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dummies= df_dummies.drop(['Consumer disputed?','Month','Day','Weeks','Issues_cleaned'],axis=1)\n",
        "df_dummies"
      ],
      "metadata": {
        "id": "-Ldy5C9zQGpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dummies_test=pd.get_dummies(te_data, prefix=['Product_dumb', 'Submitted via_dumb', 'Company response to consumer_dumb', 'Timely response?_dumb'], columns=['Product', 'Submitted via', 'Company response to consumer', 'Timely response?'])"
      ],
      "metadata": {
        "id": "1sy1wwYzRoh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dummies_test= df_dummies_test.drop(['Month','Day','Weeks','Issues_cleaned'],axis=1)\n",
        "df_dummies_test"
      ],
      "metadata": {
        "id": "9YXctKR2RzvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8hd8_Tvpoqh"
      },
      "source": [
        "Concate Dummy Variables and Drop the Original Columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data =pd.concat([tr_data,df_dummies],axis=1)"
      ],
      "metadata": {
        "id": "LKCdw1yYpNsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aU54mOOpoqi"
      },
      "outputs": [],
      "source": [
        "tr_data = tr_data.drop(['Product','Submitted via','Company response to consumer','Timely response?'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "te_data =pd.concat([te_data,df_dummies_test],axis=1)"
      ],
      "metadata": {
        "id": "yVQ_XcnwNL97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "te_data = te_data.drop(['Product','Submitted via','Company response to consumer','Timely response?'], axis = 1)"
      ],
      "metadata": {
        "id": "kT5YIeo0Nww7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data.columns"
      ],
      "metadata": {
        "id": "MuxmicDxN7jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "te_data.columns"
      ],
      "metadata": {
        "id": "Q1Zq94Z2bpgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q49q-yVxpoqi"
      },
      "source": [
        "Calculating TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsuxLlykpoqi"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "tf = TfidfVectorizer()\n",
        "issues_cleaned_train = tf.fit_transform(tr_data['Issues_cleaned']).toarray()\n",
        "issues_cleaned_test = tf.fit_transform(te_data['Issues_cleaned']).toarray()\n",
        "# print(issues_cleaned_train)\n",
        "tf_columns_train = []\n",
        "tf_columns_test = []\n",
        "for i in range(issues_cleaned_train.shape[1]):\n",
        "    tf_columns_train.append('Feature' + str(i+1))\n",
        "for i in range(issues_cleaned_test.shape[1]):\n",
        "    tf_columns_test.append('Feature' + str(i+1))\n",
        "issues_train = pd.DataFrame(issues_cleaned_train, columns = tf_columns_train)\n",
        "issues_test = pd.DataFrame(issues_cleaned_test, columns = tf_columns_test)\n",
        "# print(issues_train)\n",
        "weights = pd.DataFrame(tf.idf_, index = tf.get_feature_names_out(), columns = ['Idf_weights']).sort_values(by = 'Idf_weights', ascending = False)\n",
        "weights.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "saEmVp26kuUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxPhTO_Qpoqi"
      },
      "source": [
        "Replacing Issues_cleaned by Vectorized Issues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScmPUijrpoqi"
      },
      "outputs": [],
      "source": [
        "tr_data = tr_data.drop('Issues_cleaned', axis = 1)\n",
        "te_data = te_data.drop('Issues_cleaned', axis = 1)\n",
        "tr_data = pd.concat([tr_data, issues_train], axis = 1)\n",
        "te_data = pd.concat([te_data, issues_test], axis = 1)\n",
        "Feature168 = [0] * 119606\n",
        "te_data['Feature168'] = Feature168"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data.head()"
      ],
      "metadata": {
        "id": "K51zC-JTac_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "te_data.head()"
      ],
      "metadata": {
        "id": "fY_xaqLHagco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwK9D-o-poqj"
      },
      "source": [
        "observe train and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlTcTkPopoqj"
      },
      "outputs": [],
      "source": [
        "# df_train.head()\n",
        "# df_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xGU-cPapoqj"
      },
      "source": [
        "Observe Shape of new Train and Test Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79J9Tqjzpoqj"
      },
      "outputs": [],
      "source": [
        "tr_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "te_data.shape"
      ],
      "metadata": {
        "id": "I564gFEmYant"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1IKPOYzpoqk"
      },
      "source": [
        "Scaling the Data Sets (note:discard dependent variable before doing standardization)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy_test=te_data"
      ],
      "metadata": {
        "id": "DndJftgxyP7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy_train=tr_data"
      ],
      "metadata": {
        "id": "JSN8eYODyXyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoxQshrppoqk"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scale = StandardScaler()\n",
        "scaledX_test = scale.fit_transform(df_copy_test)\n",
        "print(scaledX_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scale = StandardScaler()\n",
        "scaledX_train = scale.fit_transform(df_copy_train)\n",
        "print(scaledX_train)"
      ],
      "metadata": {
        "id": "SusBVH4XcYzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10Pj03fYpoqk"
      },
      "source": [
        "Do feature selection with help of PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7ULlKu7poqk"
      },
      "outputs": [],
      "source": [
        "from sklearn import decomposition\n",
        "pca = decomposition.PCA()\n",
        "scaledX_train_pca = pca.fit_transform(scaledX_train)\n",
        "print(scaledX_train_pca)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su_M3P3npoqk"
      },
      "source": [
        "Select top features which are covering 80% of the information\n",
        "(n=53),\n",
        "<br>store this data into new dataframe,"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca = decomposition.PCA(n_components=0.8, whiten=True)\n",
        "scaledX_train_pca = pca.fit_transform(scaledX_train)\n",
        "print(scaledX_train_pca)"
      ],
      "metadata": {
        "id": "rqU34qJkT8nS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import decomposition\n",
        "pca = decomposition.PCA()\n",
        "scaledX_test_pca = pca.fit_transform(scaledX_test)\n",
        "print(scaledX_test_pca)"
      ],
      "metadata": {
        "id": "DguWOX6ibkdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = decomposition.PCA(n_components=0.8, whiten=True)\n",
        "scaledX_test_pca = pca.fit_transform(scaledX_test)\n",
        "print(scaledX_test_pca)"
      ],
      "metadata": {
        "id": "ZiHJ4rNOblJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfPdNUxBpoql"
      },
      "source": [
        "Split the Data Sets Into X and Y by dependent and independent variables (data selected by PCA)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktXK9RIOpoqm"
      },
      "outputs": [],
      "source": [
        "X_val=scaledX_train_pca[:,2:53]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_val.shape"
      ],
      "metadata": {
        "id": "ljA4vcS9YYdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val=scaledX_train_pca[:,0:1]"
      ],
      "metadata": {
        "id": "-rZW7RCVdXG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val.shape"
      ],
      "metadata": {
        "id": "02fz2pundgJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4liyt_jZpoqm"
      },
      "source": [
        "Split data into Train and Test datasets\n",
        "(for test data use test excel file data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "lab = LabelEncoder()\n",
        "y = lab.fit_transform(y_val)"
      ],
      "metadata": {
        "id": "Xtnxhkot5XJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_val, y, test_size = 0.2, random_state = 32, shuffle=True)\n"
      ],
      "metadata": {
        "id": "mP729Udf6oKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCl_eDoMpoqn"
      },
      "source": [
        "Shapes of the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMK5Jk7opoqo"
      },
      "outputs": [],
      "source": [
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6d3W9nbpoqp"
      },
      "source": [
        "**Model building**\n",
        "Build given models and mesure their test and validation accuracy\n",
        "build given models:\n",
        "1. LogisticRegression\n",
        "2. DecisionTreeClassifier\n",
        "3. RandomForestClassifier\n",
        "4. AdaBoostClassifier\n",
        "5. GradientBoostingClassifier\n",
        "6. KNeighborsClassifier\n",
        "7. XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "bMnIBf8Fkml2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knc = KNeighborsClassifier()\n",
        "dtc = DecisionTreeClassifier(max_depth=5)\n",
        "lrc = LogisticRegression(solver='liblinear', penalty='l1')\n",
        "rfc = RandomForestClassifier(n_estimators=50, random_state=2)\n",
        "adbt= AdaBoostClassifier(n_estimators=50,random_state=2)\n",
        "gbdt = GradientBoostingClassifier(n_estimators=50,random_state=2)\n",
        "xgb = XGBClassifier(n_estimators=50,random_state=2)"
      ],
      "metadata": {
        "id": "HJTSFagKs2Ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clfs = {\n",
        "    'KN' : knc,\n",
        "    'DT': dtc,\n",
        "    'LR': lrc,\n",
        "    'RF': rfc,\n",
        "    'ADBT':adbt,\n",
        "    'GBDT':gbdt,\n",
        "    'xgb':xgb\n",
        "}"
      ],
      "metadata": {
        "id": "lP8XRXe_s_rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBfwkKjwpoqr"
      },
      "source": [
        "Final Model and Prediction for test data file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knc = KNeighborsClassifier()\n",
        "knc.fit(X_train, y_train)\n",
        "predk = knc.predict(X_test)\n"
      ],
      "metadata": {
        "id": "MPskWQTGA-Ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,predk))"
      ],
      "metadata": {
        "id": "80zHBWtgDvmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score\n",
        "print(accuracy_score(y_test,predk))\n",
        "print(confusion_matrix(y_test,predk))\n",
        "print(precision_score(y_test,predk))"
      ],
      "metadata": {
        "id": "XQLjlhS4EBTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEMqjpS5poqr"
      },
      "source": [
        "Export Predictions to CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKDCpggppoqr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtsmRxQEpoqs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}